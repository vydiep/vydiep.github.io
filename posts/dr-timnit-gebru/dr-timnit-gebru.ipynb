{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00eb2047-4571-4975-b230-96fc5a2ac4a4",
   "metadata": {},
   "source": [
    "# What's Happening at Middlebury College?\n",
    "\n",
    "On Monday, April 24, from 7:00 pm to 8:00 pm, Dr. Timnit Gebru will be giving a virtual talk on bias and social impacts of artificial intelligence.\n",
    "\n",
    "Dr. Gebru is a prominent computer scientist and a leading voice in the field of artificial intelligence ethics. She is widely recognized for her advocacy for diversity and inclusion in the tech industry, particularly in regards to underrepresented groups such as women and people of color. She is the co-founder of Black in AI, a community of black researchers working in artificial intelligence. She is also the founder of the Distributed Artificial Intelligence Research Institute (dair), which is expected to document the effect of artifical intelligence on marginalized groups, with a focus on Africa and African immigrants in the United States. She was named one of the world's 50 greatest leaders by Fortune, one of Nature's ten people who shaped science in 2021, and one of Time's most influential people in 2022. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3103576-23db-4d5a-8b19-0eb20c7fc7d2",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a3f8c-b73b-4094-80b8-cbfe74eb83c8",
   "metadata": {},
   "source": [
    "# Dr. Gebru's Talk (Video)\n",
    "\n",
    "In her talk at the conference on Computer Vision and Pattern Recogition 2020 as part of a Tutorial on Fairness, Accountability, Transparency, and Ethics (FATE) in Computer Vision, Dr. Gebru provided an overview of the key issues and challenges in developing ethical and fair computer vision systems. \n",
    "\n",
    "She highlighted the ways in chich bias and discrimination can be embedded in the data used to train these systems, as well as the algorithms and models themselves. For example, she noted that if a training data set contains imbalances in representation across different groups, then the resulting model may be diased towards those groupds that are overrepresented in the data. This can lead to unfair outcomes, such as misclassification or exclusion of certain individuals or groups.\n",
    "\n",
    "Dr. Gebru suggested several approaches for ensuring fairness in computer vision systems, such as using representative data sets, measuring and mitigating bias in algorithms and models, and evaluating these systems on multiple fairness metrics, as different metrics may be more relevant to different applications or contexts. She emphasized the need for greater transparency and accountability in the development and deployment of computer vision systems, especially in high-stakes applications such as criminal justice and healthcare. \n",
    "\n",
    "A key takeaway from her talk is that computer vision, as used today, aren't a neutral or objective technology. These systems can have significant impacts on individuals or society as a whole, particularly in areas such as criminal justice, healthcare, and employment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11cfd9-7d54-4cb4-8bc6-95c683589c96",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18122e18-ba8b-4b77-8c9c-73fdc3f8839e",
   "metadata": {},
   "source": [
    "# Question\n",
    "\n",
    "A question for Dr. Gebru is, what steps do you believe are necessary to ensure that the development and deployment of AI systems are guided by ethical principles, and how can these principles be integrated into the broader tech industry culture especially when those who've spoken out about these problems have been \"punished\" by big tech corporations? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3f825-9b64-4350-acf6-6e11b9713d04",
   "metadata": {},
   "source": [
    "# Dr. Gebru's Talk \"At\" Middlebury (Summary and Reflection)\n",
    "\n",
    "A big takeaway of Dr. Gebru's talk is the whole concept of AGI (Artifical General Intelligence) and the parties that are involved, more specifically who's involved in the development of AGI, what's the purpose it's trying to achieve, and who's actually benefitting from it. She stated there are various definitions of AGI, one of which is \"an autonomous system that surpasses human capabilities in the majority of economically valuable tasks (Wikipedia), however, there is no one definition that is agreed upon all across the board. Despite not being a well-defined term, it is generally advertised as being able to solve everything for everyone. This sounds wonderful at first (there's a system that can solve all of our problems!!), however she continued on by pointing out critical problems underlying this concept of AGI.\n",
    "\n",
    "Dr. Gebru highlighted the unethical issues that are not talked about in media, including the exploited labor behind artifical intelligence. She explained how Kenyan workers moderate ChatGBT for less than $2 per hour. Not only is monetary compensation an issue, but also the fact that many of the workers end up traumatized by the toxic questions and comments that they need to filter out. Another problem she pointed out is how resources are not going to organizations around the world to serve their own communities, rather it's going to one big corporation. Dr. Gebru also noted that with this whole advertising of AGI being able to solve all problems, that could include health problems as well-- pointing out how it could eventually lead to a situation where poor people would get a chatbox, while rich people would get an actual doctor.\n",
    "\n",
    "I don't know how I feel after listening to her talk. I think for some parts of her argument, I couldn't really grasp/follow along, and maybe that's because of my limited background knowledge on what she was saying. However, it really shocked me when she shared things like the what Kenyan workers have to deal with or enhancing humans by merging their minds with machine (near the end of her talk)-- which is just absurd to me. There was a lot to unravel from her talk, and it left me with questions like what should we do then? Since technology is advancing everyday and more and more attention are given to AI, how can we prevent the situation from becoming too extreme? Is that even possible considering the scale of everything."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451]",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
